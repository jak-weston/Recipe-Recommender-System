{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63f8f28d-9e4d-44b5-9712-159fb3c67c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.3.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (24.1)\n",
      "Requirement already satisfied: requests in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Using pip 24.3.1 from C:\\Users\\chase_onrf9ju\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pip (python 3.11)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError.\n",
      "Check the permissions.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\chase_onrf9ju\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pip\\_internal\\commands\\install.py\", line 457, in run\n",
      "    installed = install_given_reqs(\n",
      "                ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\chase_onrf9ju\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pip\\_internal\\req\\__init__.py\", line 70, in install_given_reqs\n",
      "    requirement.install(\n",
      "  File \"C:\\Users\\chase_onrf9ju\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pip\\_internal\\req\\req_install.py\", line 867, in install\n",
      "    install_wheel(\n",
      "  File \"C:\\Users\\chase_onrf9ju\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pip\\_internal\\operations\\install\\wheel.py\", line 732, in install_wheel\n",
      "    _install_wheel(\n",
      "  File \"C:\\Users\\chase_onrf9ju\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pip\\_internal\\operations\\install\\wheel.py\", line 590, in _install_wheel\n",
      "    file.save()\n",
      "  File \"C:\\Users\\chase_onrf9ju\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pip\\_internal\\operations\\install\\wheel.py\", line 370, in save\n",
      "    os.unlink(self.dest_path)\n",
      "PermissionError: [WinError 5] Access is denied: 'C:\\\\Users\\\\chase_onrf9ju\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\numpy\\\\.libs\\\\libopenblas64__v0.3.21-gcc_10_3_0.dll'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting tensorflow==2.13.0\n",
      "  Obtaining dependency information for tensorflow==2.13.0 from https://files.pythonhosted.org/packages/9e/b8/ed5f794359d05cd0bffb894c6418da87b93016ee17b669d55c45d1bd5d5b/tensorflow-2.13.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached tensorflow-2.13.0-cp311-cp311-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting tensorflow-intel==2.13.0 (from tensorflow==2.13.0)\n",
      "  Obtaining dependency information for tensorflow-intel==2.13.0 from https://files.pythonhosted.org/packages/2f/2f/3c84f675931ce3bcbc7e23acbba1e5d7f05ce769adab48322de57a9f5928/tensorflow_intel-2.13.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached tensorflow_intel-2.13.0-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for astunparse>=1.6.0 from https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl.metadata\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for flatbuffers>=23.1.21 from https://files.pythonhosted.org/packages/41/f0/7e988a019bc54b2dbd0ad4182ef2d53488bb02e58694cd79d61369e85900/flatbuffers-24.3.25-py2.py3-none-any.whl.metadata\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for gast<=0.4.0,>=0.2.1 from https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl.metadata\n",
      "  Using cached gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for google-pasta>=0.1.1 from https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl.metadata\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=2.9.0 (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for h5py>=2.9.0 from https://files.pythonhosted.org/packages/1d/4d/cbd3014eb78d1e449b29beba1f3293a841aa8086c6f7968c383c2c7ff076/h5py-3.12.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached h5py-3.12.1-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/0b/2d/3f480b1e1d31eb3d6de5e3ef641954e5c67430d5ac93b7fa7e07589576c7/libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "  Link requires a different Python (3.11.9 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/3a/be/650f9c091ef71cb01d735775d554e068752d3ff63d7943b26316dc401749/numpy-1.21.2.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n",
      "  Link requires a different Python (3.11.9 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/5f/d6/ad58ded26556eaeaa8c971e08b6466f17c4ac4d786cd3d800e26ce59cc01/numpy-1.21.3.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n",
      "  Link requires a different Python (3.11.9 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/fb/48/b0708ebd7718a8933f0d3937513ef8ef2f4f04529f1f66ca86d873043921/numpy-1.21.4.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n",
      "  Link requires a different Python (3.11.9 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/c2/a8/a924a09492bdfee8c2ec3094d0a13f2799800b4fdc9c890738aeeb12c72e/numpy-1.21.5.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n",
      "  Link requires a different Python (3.11.9 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/45/b7/de7b8e67f2232c26af57c205aaad29fe17754f793404f59c8a730c7a191a/numpy-1.21.6.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n",
      "Collecting numpy<=1.24.3,>=1.22 (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for numpy<=1.24.3,>=1.22 from https://files.pythonhosted.org/packages/f0/e8/1ea9adebdccaadfc208c7517e09f5145ed5a73069779ff436393085d47a2/numpy-1.24.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached numpy-1.24.3-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for opt-einsum>=2.3.2 from https://files.pythonhosted.org/packages/23/cd/066e86230ae37ed0be70aae89aabf03ca8d9f39c8aea0dec8029455b5540/opt_einsum-3.4.0-py3-none-any.whl.metadata\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting packaging (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for packaging from https://files.pythonhosted.org/packages/88/ef/eb23f262cca3c0c4eb7ab1933c3b1f03d021f2c48f54763065b6f0e321be/packaging-24.2-py3-none-any.whl.metadata\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/a7/ad/bf3f358e90b7e70bf7fb520702cb15307ef268262292d3bdb16ad8ebc815/protobuf-4.25.5-cp310-abi3-win_amd64.whl.metadata\n",
      "  Using cached protobuf-4.25.5-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting setuptools (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for setuptools from https://files.pythonhosted.org/packages/55/21/47d163f615df1d30c094f6c8bbb353619274edccf0327b185cc2493c2c33/setuptools-75.6.0-py3-none-any.whl.metadata\n",
      "  Using cached setuptools-75.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting six>=1.12.0 (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for six>=1.12.0 from https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for termcolor>=1.1.0 from https://files.pythonhosted.org/packages/7f/be/df630c387a0a054815d60be6a97eb4e8f17385d5d6fe660e1c02750062b4/termcolor-2.5.0-py3-none-any.whl.metadata\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for typing-extensions<4.6.0,>=3.6.6 from https://files.pythonhosted.org/packages/31/25/5abcd82372d3d4a3932e1fa8c3dbf9efac10cc7c0d16e78467460571b404/typing_extensions-4.5.0-py3-none-any.whl.metadata\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for wrapt>=1.11.0 from https://files.pythonhosted.org/packages/63/bb/c293a67fb765a2ada48f48cd0f2bb957da8161439da4c03ea123b9894c02/wrapt-1.17.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached wrapt-1.17.0-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/4b/29/061c93a35f498238dc35eb8fb039ce168aa99cac2f0f1ce0c8a0a4bdb274/grpcio-1.68.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached grpcio-1.68.1-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for tensorboard<2.14,>=2.13 from https://files.pythonhosted.org/packages/67/f2/e8be5599634ff063fa2c59b7b51636815909d5140a26df9f02ce5d99b81a/tensorboard-2.13.0-py3-none-any.whl.metadata\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for tensorflow-estimator<2.14,>=2.13.0 from https://files.pythonhosted.org/packages/72/5c/c318268d96791c6222ad7df1651bbd1b2409139afeb6f468c0f327177016/tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for keras<2.14,>=2.13.1 from https://files.pythonhosted.org/packages/2e/f3/19da7511b45e80216cbbd9467137b2d28919c58ba1ccb971435cb631e470/keras-2.13.1-py3-none-any.whl.metadata\n",
      "  Using cached keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Link requires a different Python (3.11.9 not in: '>=3.7, <3.11'): https://files.pythonhosted.org/packages/0e/99/d2e8e6b9269a53fdbcacc11f0fb8d6a44a1d0b4118043e892102a4f85d75/tensorflow_io_gcs_filesystem-0.28.0-cp311-cp311-win_amd64.whl (from https://pypi.org/simple/tensorflow-io-gcs-filesystem/) (requires-python:>=3.7, <3.11)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for tensorflow-io-gcs-filesystem>=0.23.1 from https://files.pythonhosted.org/packages/ac/4e/9566a313927be582ca99455a9523a097c7888fc819695bdc08415432b202/tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for wheel<1.0,>=0.23.0 from https://files.pythonhosted.org/packages/0b/2c/87f3254fd8ffd29e4c02732eee68a83a1d3c346ae39bc6822dcbcb697f2b/wheel-0.45.1-py3-none-any.whl.metadata\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/2d/9a/3d5087d27865c2f0431b942b5c4500b7d1b744dd3262fdc973a4c39d099e/google_auth-2.36.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached google_auth-2.36.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for google-auth-oauthlib<1.1,>=0.5 from https://files.pythonhosted.org/packages/4a/07/8d9a8186e6768b55dfffeb57c719bc03770cf8a970a074616ae6f9e26a57/google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for markdown>=2.6.8 from https://files.pythonhosted.org/packages/3f/08/83871f3c50fc983b88547c196d11cf8c3340e37c32d2e9d6152abe2c61f7/Markdown-3.7-py3-none-any.whl.metadata\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for requests<3,>=2.21.0 from https://files.pythonhosted.org/packages/f9/9b/335f9764261e915ed497fcdeb11df5dfd6f7bf257d4a6a2a686d80da4d54/requests-2.32.3-py3-none-any.whl.metadata\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/7a/13/e503968fefabd4c6b2650af21e110aa8466fe21432cd7c43a84577a89438/tensorboard_data_server-0.7.2-py3-none-any.whl.metadata\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for werkzeug>=1.0.1 from https://files.pythonhosted.org/packages/52/24/ab44c871b0f07f491e5d2ad12c9bd7358e527510618cb1b803a88e986db1/werkzeug-3.1.3-py3-none-any.whl.metadata\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a4/07/14f8ad37f2d12a5ce41206c21820d8cb6561b728e51fad4530dff0552a67/cachetools-5.5.0-py3-none-any.whl.metadata\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for pyasn1-modules>=0.2.1 from https://files.pythonhosted.org/packages/77/89/bc88a6711935ba795a679ea6ebee07e128050d6382eaa35a0a47c8032bdc/pyasn1_modules-0.4.1-py3-none-any.whl.metadata\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for rsa<5,>=3.1.4 from https://files.pythonhosted.org/packages/49/97/fa78e3d2f65c02c8e1268b9aba606569fe97f6c8f7c2d74394553347c145/rsa-4.9-py3-none-any.whl.metadata\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for requests-oauthlib>=0.7.0 from https://files.pythonhosted.org/packages/3b/5d/63d4ae3b9daea098d5d6f5da83984853c1bbacd5dc826764b249fe119d24/requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/0b/6e/b13bd47fa9023b3699e94abf565b5a2f0b0be6e9ddac9812182596ee62e4/charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for idna<4,>=2.5 from https://files.pythonhosted.org/packages/76/c6/c88e154df9c4e1a2a66ccf0005a88dfb2650c1dffb6f5ce603dfbd452ce3/idna-3.10-py3-none-any.whl.metadata\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/ce/d9/5f4c13cecde62396b0d3fe530a50ccea91e7dfc1ccf0e09c228841bb5ba8/urllib3-2.2.3-py3-none-any.whl.metadata\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for certifi>=2017.4.17 from https://files.pythonhosted.org/packages/12/90/3c9ff0512038035f59d279fddeb79f5f1eccd8859f06d6163c58798b9487/certifi-2024.8.30-py3-none-any.whl.metadata\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for MarkupSafe>=2.1.1 from https://files.pythonhosted.org/packages/da/b8/3a3bd761922d416f3dc5d00bfbed11f66b1ab89a0c2b6e887240a30b0f6b/MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for pyasn1<0.7.0,>=0.4.6 from https://files.pythonhosted.org/packages/c8/f1/d6a797abb14f6283c0ddff96bbdd46937f64122b8c925cab503dd37f8214/pyasn1-0.6.1-py3-none-any.whl.metadata\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow==2.13.0)\n",
      "  Obtaining dependency information for oauthlib>=3.0.0 from https://files.pythonhosted.org/packages/7e/80/cab10959dc1faead58dc8384a781dfbf93cb4d33d50988f7a69f1b7c9bbe/oauthlib-3.2.2-py3-none-any.whl.metadata\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Using cached tensorflow-2.13.0-cp311-cp311-win_amd64.whl (1.9 kB)\n",
      "Using cached tensorflow_intel-2.13.0-cp311-cp311-win_amd64.whl (276.6 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.68.1-cp311-cp311-win_amd64.whl (4.4 MB)\n",
      "Using cached h5py-3.12.1-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached numpy-1.24.3-cp311-cp311-win_amd64.whl (14.8 MB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Using cached setuptools-75.6.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Using cached wrapt-1.17.0-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached google_auth-2.36.0-py2.py3-none-any.whl (209 kB)\n",
      "Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl (101 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, setuptools, pyasn1, protobuf, packaging, opt-einsum, oauthlib, numpy, MarkupSafe, markdown, keras, idna, grpcio, gast, charset-normalizer, certifi, cachetools, absl-py, werkzeug, rsa, requests, pyasn1-modules, h5py, google-pasta, astunparse, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Requirement already satisfied: pandas in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from seaborn) (1.24.3)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chase_onrf9ju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub --upgrade\n",
    "!pip install -Iv tensorflow==2.13.0\n",
    "!pip install pandas\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fbd7100-ad97-4b14-a8f3-50690ca5e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dc9392e-b281-4982-b683-99bd4b7c9ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/shuyangli94/food-com-recipes-and-user-interactions?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267M/267M [00:05<00:00, 48.5MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\chase_onrf9ju\\.cache\\kagglehub\\datasets\\shuyangli94\\food-com-recipes-and-user-interactions\\versions\\2\n",
      "Files in the dataset: ['ingr_map.pkl', 'interactions_test.csv', 'interactions_train.csv', 'interactions_validation.csv', 'PP_recipes.csv', 'PP_users.csv', 'RAW_interactions.csv', 'RAW_recipes.csv']\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"shuyangli94/food-com-recipes-and-user-interactions\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# List all files in the dataset directory\n",
    "dataset_files = os.listdir(path)\n",
    "print(\"Files in the dataset:\", dataset_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51ca66d0-9b01-4e3d-bafa-a18b988e514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading interactions_test.csv into a DataFrame...\n",
      "Loaded interactions_test.csv with 12455 rows and 6 columns.\n",
      "Loading interactions_train.csv into a DataFrame...\n",
      "Loaded interactions_train.csv with 698901 rows and 6 columns.\n",
      "Loading interactions_validation.csv into a DataFrame...\n",
      "Loaded interactions_validation.csv with 7023 rows and 6 columns.\n",
      "Loading PP_recipes.csv into a DataFrame...\n",
      "Loaded PP_recipes.csv with 178265 rows and 8 columns.\n",
      "Loading PP_users.csv into a DataFrame...\n",
      "Loaded PP_users.csv with 25076 rows and 6 columns.\n",
      "Loading RAW_interactions.csv into a DataFrame...\n",
      "Loaded RAW_interactions.csv with 1132367 rows and 5 columns.\n",
      "Loading RAW_recipes.csv into a DataFrame...\n",
      "Loaded RAW_recipes.csv with 231637 rows and 12 columns.\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store DataFrames for each useful file\n",
    "dataframes = {}\n",
    "\n",
    "# Load each useful CSV file into a DataFrame dictionary\n",
    "for file_name in dataset_files:\n",
    "    file_path = os.path.join(path, file_name)\n",
    "    if file_name.endswith('.csv') and os.path.exists(file_path):\n",
    "        print(f\"Loading {file_name} into a DataFrame...\")\n",
    "        df_name = file_name.split('.')[0]  # Use filename without extension as key\n",
    "        dataframes[df_name] = pd.read_csv(file_path)\n",
    "        print(f\"Loaded {file_name} with {dataframes[df_name].shape[0]} rows and {dataframes[df_name].shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a48c4712-e891-4912-9400-6778c70ae809",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_interactions_df = dataframes.get('RAW_interactions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9cda476a-2658-41c7-94e4-c9c06eb1f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate userIDs, recipeIDs, and put interactions into a set\n",
    "userIDs = {}\n",
    "recipeIDs = {}\n",
    "interactions = []\n",
    "\n",
    "for i in range(raw_interactions_df.shape[0]):\n",
    "    row = raw_interactions_df.iloc[i]\n",
    "    user = row['user_id']\n",
    "    recipe = row['recipe_id']\n",
    "    rating = row['rating']\n",
    "    if not user in userIDs: userIDs[user] = len(userIDs)\n",
    "    if not recipe in recipeIDs: recipeIDs[recipe] = len(recipeIDs)\n",
    "    interactions.append((user,recipe,rating))\n",
    "\n",
    "random.shuffle(interactions)\n",
    "\n",
    "# Split interactions into training and testing sets\n",
    "nTrain = int(len(interactions) * 0.9)\n",
    "nTest = len(interactions) - nTrain\n",
    "interactionsTrain = interactions[:nTrain]\n",
    "interactionsTest = interactions[nTrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3068be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the recipes per user, users per recipe, and global average rating\n",
    "recipesPerUser = defaultdict(list)\n",
    "usersPerRecipe = defaultdict(list)\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerRecipe = defaultdict(list)\n",
    "for user,recipe,rating in interactionsTrain:\n",
    "    recipesPerUser[user].append(recipe)\n",
    "    usersPerRecipe[recipe].append(user)\n",
    "    ratingsPerUser[user].append(rating)\n",
    "    ratingsPerRecipe[recipe].append(rating)\n",
    "\n",
    "globalAvg = sum([rating for _,_,rating in interactionsTrain]) / len(interactionsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ea1a179-759e-41f8-b50a-117b37c8fd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE (Using Global Averages) = 1.5848681885817457\n"
     ]
    }
   ],
   "source": [
    "# Baseline: Find MSE of predicting global average every time\n",
    "MSE = 0\n",
    "for user,recipe,rating in interactionsTest:\n",
    "    error = (rating - globalAvg) ** 2\n",
    "    MSE += error\n",
    "\n",
    "MSE /= len(interactionsTest)\n",
    "\n",
    "print(\"Test MSE (Using Global Averages) = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ded8b019-c64c-4b86-bae9-6162ce65761c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE (Using User Averages) = 1.5632766663314015\n"
     ]
    }
   ],
   "source": [
    "# Baseline: Find MSE of predicting user average, or global average if there is none\n",
    "MSE = 0\n",
    "for user,recipe,rating in interactionsTest:\n",
    "    if user in recipesPerUser:\n",
    "        avgUserRating = sum(ratingsPerUser[user]) / len(ratingsPerUser[user])\n",
    "        error = (rating - avgUserRating) ** 2\n",
    "    else:\n",
    "        error = (rating - globalAvg) ** 2\n",
    "    MSE += error\n",
    "\n",
    "MSE /= len(interactionsTest)\n",
    "\n",
    "print(\"Test MSE (Using User Averages) = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5f5e76f0-9f7c-427c-8363-accdda29c1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE (Using Recipe Averages) = 1.7537650753993466\n"
     ]
    }
   ],
   "source": [
    "# Baseline: Find MSE of predicting recipe average, or global average if there is none\n",
    "MSE = 0\n",
    "for user,recipe,rating in interactionsTest:\n",
    "    if recipe in usersPerRecipe:\n",
    "        avgRecipeRating = sum(ratingsPerRecipe[recipe]) / len(ratingsPerRecipe[recipe])\n",
    "        error = (rating - avgRecipeRating) ** 2\n",
    "    else:\n",
    "        error = (rating - globalAvg) ** 2\n",
    "    MSE += error\n",
    "\n",
    "MSE /= len(interactionsTest)\n",
    "\n",
    "print(\"Test MSE (Using Recipe Averages) = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4453618d-b9e5-4c64-a14d-54be18af9cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE (Using Either Average) = 1.522573740651676\n"
     ]
    }
   ],
   "source": [
    "# Baseline: Find MSE of predicting recipe average or user average depending on total count, or global average if there is none\n",
    "MSE = 0\n",
    "for user,recipe,rating in interactionsTest:\n",
    "    if recipe in usersPerRecipe and (user not in recipesPerUser or len(usersPerRecipe[recipe]) >= len(recipesPerUser[user])):\n",
    "        avgRecipeRating = sum(ratingsPerRecipe[recipe]) / len(ratingsPerRecipe[recipe])\n",
    "        error = (rating - avgRecipeRating) ** 2\n",
    "    elif user in recipesPerUser and (recipe not in usersPerRecipe or len(usersPerRecipe[recipe]) <= len(recipesPerUser[user])):\n",
    "        avgUserRating = sum(ratingsPerUser[user]) / len(ratingsPerUser[user])\n",
    "        error = (rating - avgUserRating) ** 2\n",
    "    else:\n",
    "        error = (rating - globalAvg) ** 2\n",
    "    MSE += error\n",
    "\n",
    "MSE /= len(interactionsTest)\n",
    "\n",
    "print(\"Test MSE (Using Either Average) = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b309bba-e402-43a2-8e5e-f3e6c2925e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent Factor Model to be used for our predictive problem\n",
    "\n",
    "class LatentFactorModel(tf.keras.Model):\n",
    "    def __init__(self, mu, K, lamb):\n",
    "        super(LatentFactorModel, self).__init__()\n",
    "        # Initialize to average\n",
    "        self.alpha = tf.cast(tf.Variable(mu), dtype=tf.float32)\n",
    "        # Initialize to small random values\n",
    "        self.betaU = tf.Variable(tf.random.normal([len(userIDs)],stddev=0.001))\n",
    "        self.betaR = tf.Variable(tf.random.normal([len(recipeIDs)],stddev=0.001))\n",
    "        self.gammaU = tf.Variable(tf.random.normal([len(userIDs),K],stddev=0.001))\n",
    "        self.gammaR = tf.Variable(tf.random.normal([len(recipeIDs),K],stddev=0.001))\n",
    "        self.lamb = lamb\n",
    "\n",
    "    # Prediction for a single instance (useful for evaluation)\n",
    "    def predict(self, u, r):\n",
    "        prediction = self.alpha + self.betaU[u] + self.betaR[r] +\\\n",
    "            tf.tensordot(self.gammaU[u], self.gammaR[r], 1)\n",
    "        return prediction\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "        return self.lamb * (tf.reduce_sum(self.betaU**2) +\\\n",
    "                            tf.reduce_sum(self.betaR**2) +\\\n",
    "                            tf.reduce_sum(self.gammaU**2) +\\\n",
    "                            tf.reduce_sum(self.gammaR**2))\n",
    "    \n",
    "    # Prediction for a sample of instances\n",
    "    def predictSample(self, sampleU, sampleR):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
    "        r = tf.convert_to_tensor(sampleR, dtype=tf.int32)\n",
    "        beta_u = tf.nn.embedding_lookup(self.betaU, u)\n",
    "        beta_r = tf.nn.embedding_lookup(self.betaR, r)\n",
    "        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n",
    "        gamma_r = tf.nn.embedding_lookup(self.gammaR, r)\n",
    "        prediction = self.alpha + beta_u + beta_r + tf.reduce_sum(tf.multiply(gamma_u, gamma_r), 1)\n",
    "        return prediction\n",
    "    \n",
    "    # Loss\n",
    "    def call(self, sampleUser, sampleRecipe, sampleRating):\n",
    "        prediction = self.predictSample(sampleUser, sampleRecipe)\n",
    "        rating = tf.convert_to_tensor(sampleRating, dtype=tf.float32)\n",
    "        return tf.nn.l2_loss(prediction - rating) / len(sampleRating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a7d7d-0009-4b41-95d1-1e62757b7f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our optimizer and model\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.1)\n",
    "modelLFM = LatentFactorModel(globalAvg, 12, 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebcdea9-38b7-48e8-93d5-02d147adf2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One iteration of our training step\n",
    "\n",
    "def trainingStep(model, interactions):\n",
    "    Nsamples = 250000\n",
    "    with tf.GradientTape() as tape:\n",
    "        sampleUser, sampleRecipe, sampleRating = [], [], []\n",
    "        for _ in range(Nsamples):\n",
    "            user,recipe,rating = random.choice(interactions)\n",
    "            sampleUser.append(userIDs[user])\n",
    "            sampleRecipe.append(recipeIDs[recipe])\n",
    "            sampleRating.append(rating)\n",
    "\n",
    "        loss = model(sampleUser,sampleRecipe,sampleRating)\n",
    "        loss += model.reg()\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients((grad, var) for\n",
    "                              (grad, var) in zip(gradients, model.trainable_variables)\n",
    "                              if grad is not None)\n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d876534e-789b-4d07-b67b-25f8ba6db00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1, objective = 0.80425376\n",
      "iteration 2, objective = 0.7704608\n",
      "iteration 3, objective = 0.7510032\n",
      "iteration 4, objective = 0.7427501\n",
      "iteration 5, objective = 0.74849945\n",
      "iteration 6, objective = 0.7379982\n",
      "iteration 7, objective = 0.7377526\n",
      "iteration 8, objective = 0.74505186\n",
      "iteration 9, objective = 0.73226947\n",
      "iteration 10, objective = 0.7289218\n",
      "iteration 11, objective = 0.7298265\n",
      "iteration 12, objective = 0.7385655\n",
      "iteration 13, objective = 0.73044527\n",
      "iteration 14, objective = 0.7353144\n",
      "iteration 15, objective = 0.73535186\n",
      "iteration 16, objective = 0.73569643\n",
      "iteration 17, objective = 0.7369458\n",
      "iteration 18, objective = 0.73214436\n",
      "iteration 19, objective = 0.72963095\n",
      "iteration 20, objective = 0.73205996\n",
      "iteration 21, objective = 0.73308593\n",
      "iteration 22, objective = 0.734856\n",
      "iteration 23, objective = 0.7324256\n",
      "iteration 24, objective = 0.73736537\n",
      "iteration 25, objective = 0.73690605\n",
      "iteration 26, objective = 0.74310726\n",
      "iteration 27, objective = 0.73716605\n",
      "iteration 28, objective = 0.72463596\n",
      "iteration 29, objective = 0.73184687\n",
      "iteration 30, objective = 0.73786414\n",
      "iteration 31, objective = 0.74216574\n",
      "iteration 32, objective = 0.7390652\n",
      "iteration 33, objective = 0.7441269\n",
      "iteration 34, objective = 0.7352577\n",
      "iteration 35, objective = 0.73834246\n",
      "iteration 36, objective = 0.7398389\n",
      "iteration 37, objective = 0.7454887\n",
      "iteration 38, objective = 0.7446814\n",
      "iteration 39, objective = 0.74092776\n",
      "iteration 40, objective = 0.7429005\n",
      "iteration 41, objective = 0.73942935\n",
      "iteration 42, objective = 0.7481112\n",
      "iteration 43, objective = 0.737789\n",
      "iteration 44, objective = 0.7467277\n",
      "iteration 45, objective = 0.7381501\n",
      "iteration 46, objective = 0.74720013\n",
      "iteration 47, objective = 0.7429662\n",
      "iteration 48, objective = 0.73941094\n",
      "iteration 49, objective = 0.7459281\n",
      "iteration 50, objective = 0.74464655\n",
      "iteration 51, objective = 0.7456781\n",
      "iteration 52, objective = 0.74327797\n",
      "iteration 53, objective = 0.7396618\n",
      "iteration 54, objective = 0.74109524\n",
      "iteration 55, objective = 0.7496661\n",
      "iteration 56, objective = 0.74161065\n",
      "iteration 57, objective = 0.7430849\n",
      "iteration 58, objective = 0.7373697\n",
      "iteration 59, objective = 0.7438123\n",
      "iteration 60, objective = 0.7402437\n",
      "iteration 61, objective = 0.7500339\n",
      "iteration 62, objective = 0.7529154\n",
      "iteration 63, objective = 0.74505264\n",
      "iteration 64, objective = 0.7477889\n",
      "iteration 65, objective = 0.74502575\n",
      "iteration 66, objective = 0.7402692\n",
      "iteration 67, objective = 0.74383193\n",
      "iteration 68, objective = 0.7476876\n",
      "iteration 69, objective = 0.74404484\n",
      "iteration 70, objective = 0.7447619\n",
      "iteration 71, objective = 0.7458799\n",
      "iteration 72, objective = 0.73760426\n",
      "iteration 73, objective = 0.7365619\n",
      "iteration 74, objective = 0.73812103\n",
      "iteration 75, objective = 0.74354976\n",
      "iteration 76, objective = 0.7380939\n",
      "iteration 77, objective = 0.7464663\n",
      "iteration 78, objective = 0.742244\n",
      "iteration 79, objective = 0.74306524\n",
      "iteration 80, objective = 0.7454587\n",
      "iteration 81, objective = 0.7389172\n",
      "iteration 82, objective = 0.7393576\n",
      "iteration 83, objective = 0.7405344\n",
      "iteration 84, objective = 0.7440143\n",
      "iteration 85, objective = 0.7448615\n",
      "iteration 86, objective = 0.7482771\n",
      "iteration 87, objective = 0.74592435\n",
      "iteration 88, objective = 0.74228185\n",
      "iteration 89, objective = 0.7443461\n",
      "iteration 90, objective = 0.7377619\n",
      "iteration 91, objective = 0.74512744\n",
      "iteration 92, objective = 0.7500917\n",
      "iteration 93, objective = 0.7433066\n",
      "iteration 94, objective = 0.7473591\n",
      "iteration 95, objective = 0.7324977\n",
      "iteration 96, objective = 0.7480456\n",
      "iteration 97, objective = 0.7356459\n",
      "iteration 98, objective = 0.75274587\n",
      "iteration 99, objective = 0.7446039\n",
      "iteration 100, objective = 0.7384869\n"
     ]
    }
   ],
   "source": [
    "# Iterate through 100 runs to fine tune our model\n",
    "\n",
    "for i in range(100):\n",
    "    obj = trainingStep(modelLFM, interactionsTrain)\n",
    "    print(\"iteration \" + str(i+1) + \", objective = \" + str(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f073f0-f18d-41ba-8f59-6e8ad8f96d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE = 1.4894706010818481\n"
     ]
    }
   ],
   "source": [
    "# Testing our model\n",
    "\n",
    "MSE = 0\n",
    "\n",
    "predictions = modelLFM.predictSample([userIDs[interaction[0]] for interaction in interactionsTest],[recipeIDs[interaction[1]] for interaction in interactionsTest])\n",
    "\n",
    "for i in range(len(interactionsTest)):\n",
    "    MSE += (interactionsTest[i][2] - predictions[i]) ** 2\n",
    "\n",
    "MSE /= len(interactionsTest)\n",
    "print(\"Test MSE = \" + str(float(MSE)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
